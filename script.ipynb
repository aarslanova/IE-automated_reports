{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94c876fb",
   "metadata": {},
   "source": [
    "# Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872ba4a9",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf458793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from shutil import copyfile\n",
    "from xlsxwriter.utility import xl_col_to_name\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4198be",
   "metadata": {},
   "source": [
    "## Set ups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbe0cfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to the working directory\n",
    "wd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f072299",
   "metadata": {},
   "source": [
    "## Harvest the data and task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1592a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data as a DataFrame\n",
    "plan = pd.read_excel(wd + '/data/plan.xlsx', header=None, skiprows=2, na_values=[' ', '-'])\n",
    "# Convert a spreadsheet number to its column letter\n",
    "header = plan.columns.tolist()\n",
    "plan.columns = [xl_col_to_name(x) for x in header]\n",
    "# Drop anonymous participants\n",
    "plan.dropna(subset=['I', 'J'], inplace=True)\n",
    "plan.reset_index(drop=True, inplace=True)\n",
    "# Add Full name column\n",
    "plan['I'] = plan['I'].astype('str')\n",
    "plan['J'] = plan['J'].astype('str')\n",
    "plan['Full name'] = plan['I'] + ' ' + plan['J']\n",
    "plan = plan[plan['Full name'].map(len) > 10]\n",
    "\n",
    "# Import the task as a ExcelFile\n",
    "task = pd.ExcelFile(wd + '/templates/template_plan.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550775da",
   "metadata": {},
   "source": [
    "## Modify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20432c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the data using custom mappers\n",
    "with open(wd +'/data/' + 'subdivisions.txt', 'r') as txt_file:\n",
    "    for line in txt_file:\n",
    "        subdivisions = line.strip('[').strip(']').replace(\"'\", \"\").split(',')\n",
    "subdivision_decoder = dict(zip([x for x in range(1, 32) if x != 10], subdivisions))\n",
    "plan['K'] = plan['K'].map(subdivision_decoder)      \n",
    "\n",
    "with open(wd +'/data/' + 'occupation.txt', 'r') as txt_file:\n",
    "    for line in txt_file:\n",
    "        occupation = line.strip('[').strip(']').replace(\"'\", \"\").split(',')\n",
    "occupation_decoder = dict(zip([x for x in range(1, 16)] + [97], occupation))\n",
    "plan['L'] = plan['L'].map(occupation_decoder)\n",
    "\n",
    "rx_decoder = {1: 'Проводить очные консультации обучающимся (индивидуальные и групповые) вне рамок дисциплин'}\n",
    "ry_decoder = {1: 'Читать и рецензировать письменные работы обучающихся, включая ВКР и диссертационные работы, участвовать в защитах ВКР и диссертационных работ'}\n",
    "rz_decoder = {1: 'Проводить разные виды учебных и производственных практик, школ, экспедиций'}\n",
    "sb_decoder = {1: 'Не планирую выполнять иную образовательную деятельность, связанную с преподаванием дисциплин и научным руководством'}\n",
    "sc_decoder = {1: 'Не планирую выполнять иную образовательную деятельность'}\n",
    "\n",
    "plan['RX'] = plan['RX'].map(rx_decoder)\n",
    "plan['RY'] = plan['RY'].map(ry_decoder)\n",
    "plan['RZ'] = plan['RZ'].map(rz_decoder)\n",
    "plan['SB'] = plan['SB'].map(sb_decoder)\n",
    "plan['SC'] = plan['SC'].map(sc_decoder)\n",
    "\n",
    "origin = pd.read_excel(wd + '/data/plan.xlsx', header=None)\n",
    "header = origin.columns\n",
    "origin.columns = [xl_col_to_name(x) for x in header]\n",
    "columns = ['LM', 'LN', 'LO', 'LP', 'LQ', 'LR',\n",
    "           'LS', 'LT', 'LU', 'LV', 'LW', 'LX',\n",
    "           'LY', 'LZ', 'MA', 'MB', 'MC', 'MD',\n",
    "           'ME', 'MF', 'MG', 'MH', 'MI', 'MJ',\n",
    "           'MK', 'ML', 'MN', 'MO', 'MP',\n",
    "           'MQ', 'MR', 'MS', 'MT', 'MU', 'MV',\n",
    "           'MW', 'MX', 'MY', 'MZ', 'NA', 'NB',\n",
    "           'NC', 'ND', 'NE', 'NF', 'NG', 'NH',\n",
    "           'NI', 'NK', 'NL', 'NM', 'NN',\n",
    "           'NO', 'NQ', 'NS', 'NT', 'NU',\n",
    "           'NV', 'NW', 'NX', 'NY', 'NZ', 'OA',\n",
    "           'OB', 'OC', 'OE', 'OF', 'OG']\n",
    "origin = origin.loc[:, columns]\n",
    "mapper = dict(origin.iloc[1])\n",
    "for k, v in mapper.items():\n",
    "    mapper[k] = str(v.split(' - ')[-1])\n",
    "\n",
    "for column in columns:\n",
    "    if not column in ['MN', 'NK', 'NQ', 'NS', 'OE', 'OF', 'OG']:\n",
    "        plan[column] = plan[column].map({1: mapper[column]}) \n",
    "    else:\n",
    "        continue\n",
    "\n",
    "plan['LSOG'] = plan['LS'] + ': ' + plan['OG']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e71a84",
   "metadata": {},
   "source": [
    "## Parse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c2eb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n",
      "1.1.\n",
      "1.2.\n",
      "1.3.\n",
      "1.4.\n",
      "1.5.\n",
      "2\n",
      "3\n",
      "4\n",
      "5.1\n",
      "5.2\n",
      "5.3.\n",
      "5.4\n",
      "5.5.\n",
      "6.1.\n",
      "6.2.\n",
      "6.3.\n",
      "6.4.\n",
      "6.5.\n",
      "6.6.\n",
      "6.7.\n",
      "7.1.\n",
      "7.2.\n",
      "7.3.\n",
      "8\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "sheets_to_consider = ['1.1.', '1.2.', '1.3.', '1.4.', '1.5.',\n",
    "                      '2', '3', '4',\n",
    "                      '5.1', '5.2', '5.3.', '5.4', '5.5.',\n",
    "                      '6.1.', '6.2.', '6.3.', '6.4.', '6.5.', '6.6.', '6.7.',\n",
    "                      '7.1.', '7.2.', '7.3.',\n",
    "                      '8', '10', '11']\n",
    "\n",
    "for subdivision in subdivisions:\n",
    "    file_name = wd + '/results/plan/' + subdivision + '_план_2023' + '.xlsx'\n",
    "    # Copy the teplate for each subdivision\n",
    "    copyfile(wd + '/templates/' + 'template_plan_final.xlsx', file_name)\n",
    "    # Load the file\n",
    "    workbook = load_workbook(file_name)\n",
    "    # Select observations\n",
    "    subset = plan[plan['K'] == subdivision]\n",
    "    \n",
    "    for sheet_name in sheets_to_consider:\n",
    "        print(sheet_name)\n",
    "        # Parse a particular sheet and save it as a DataFrame\n",
    "        sheet = task.parse(sheet_name=sheet_name, skiprows=1)\n",
    "        # Drop NaNs\n",
    "        sheet.dropna(how='all', inplace=True)\n",
    "        # Drop useless column\n",
    "        sheet.drop(columns='№', inplace=True)\n",
    "        # Save headers\n",
    "        header = sheet.columns\n",
    "        \n",
    "        # Initialize a list for DataFrames\n",
    "        dfs = []\n",
    "        \n",
    "        # Iterate over each row\n",
    "        for i, data in sheet.iterrows():\n",
    "            values = data.values.tolist()\n",
    "            if sheet_name == '4':\n",
    "                if pd.Series(values).isna().sum() >= 1:\n",
    "                    values.pop()\n",
    "                    values.extend(['NA'])\n",
    "                # Select needed columns and drop missing values\n",
    "                df = subset.loc[:, values].dropna(thresh=1)\n",
    "                # Use initial column names\n",
    "                df.columns = header\n",
    "                # Append the obtained DataFrame to the list of DataFrames\n",
    "                dfs.append(df)\n",
    "                \n",
    "            elif sheet_name in ['2', '3', '6.4.', '6.5.', '6.6.', '6.7.', '7.3.', '10', '11']:\n",
    "                # Select needed columns and drop rows with less than 1 non-missing value\n",
    "                df = subset.loc[:, data.values].dropna(thresh=1)\n",
    "                # Use initial column names\n",
    "                df.columns = header\n",
    "                # Append the obtained DataFrame to the list of DataFrames\n",
    "                dfs.append(df)\n",
    "            else:\n",
    "                # Select needed columns and drop rows with less than 2 non-missing value\n",
    "                df = subset.loc[:, data.values].dropna(thresh=2)\n",
    "                # Use initial column names\n",
    "                df.columns = header\n",
    "                # Append the obtained DataFrame to the list of DataFrames\n",
    "                dfs.append(df)\n",
    "\n",
    "        # Concat the DataFrames\n",
    "        dfs = pd.concat(dfs, ignore_index=True)\n",
    "        # Save index as a column\n",
    "        dfs.reset_index(inplace=True)\n",
    "        # Change index so that it starts with 1\n",
    "        dfs['index'] = dfs['index'] + 1\n",
    "        \n",
    "        # Get access to the particular sheet\n",
    "        worksheet = workbook[sheet_name]\n",
    "        # Turn the DataFrame into Generator object dataframe_to_rows\n",
    "        rows = dataframe_to_rows(dfs, index=False, header=False)\n",
    "        # Write data directly in the current Excel sheet\n",
    "        for r_idx, row in enumerate(rows, 3):\n",
    "            for c_idx, value in enumerate(row, 1):\n",
    "                worksheet.cell(row=r_idx, column=c_idx, value=value)\n",
    "    # Save the updated Excel file\n",
    "    workbook.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3a69fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b179d3c1",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f691c59e",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0afb87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from shutil import copyfile\n",
    "from xlsxwriter.utility import xl_col_to_name\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0524c979",
   "metadata": {},
   "source": [
    "## Set ups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca015337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to the working directory\n",
    "wd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272b411f",
   "metadata": {},
   "source": [
    "## Harvest the data and task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5dc17e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data as a DataFrame\n",
    "report = pd.read_excel(wd + '/data/report.xlsx', header=None, skiprows=2, na_values=[' ', '-'])\n",
    "# Convert a spreadsheet number to its column letter\n",
    "header = report.columns.tolist()\n",
    "report.columns = [xl_col_to_name(x) for x in header]\n",
    "# Drop anonymous participants\n",
    "report.dropna(subset=['I', 'J'], inplace=True)\n",
    "report.reset_index(drop=True, inplace=True)\n",
    "# Add Full name column\n",
    "report['I'] = report['I'].astype('str')\n",
    "report['J'] = report['J'].astype('str')\n",
    "report['Full name'] = report['I'] + ' ' + report['J']\n",
    "report = report[report['Full name'].map(len) > 10]\n",
    "\n",
    "# Import the task as a ExcelFile\n",
    "task = pd.ExcelFile(wd + '/templates/template_report.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80715ae1",
   "metadata": {},
   "source": [
    "## Modify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20c40746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the data using custom mappers\n",
    "with open(wd +'/data/' + 'subdivisions.txt', 'r') as txt_file:\n",
    "    for line in txt_file:\n",
    "        subdivisions = line.strip('[').strip(']').replace(\"'\", \"\").split(',')\n",
    "subdivision_decoder = dict(zip([x for x in range(1, 32) if x != 10], subdivisions))\n",
    "report['K'] = report['K'].map(subdivision_decoder)      \n",
    "\n",
    "with open(wd +'/data/' + 'occupation.txt', 'r') as txt_file:\n",
    "    for line in txt_file:\n",
    "        occupation = line.strip('[').strip(']').replace(\"'\", \"\").split(',')\n",
    "occupation_decoder = dict(zip([x for x in range(1, 16)] + [97], occupation))\n",
    "report['L'] = report['L'].map(occupation_decoder)\n",
    "\n",
    "po_decoder = {1: 'Проводил(а) очные консультации обучающимся (индивидуальные и групповые) вне рамок дисциплин'}\n",
    "pp_decoder = {1: 'Читал(а) и рецензировал(а) письменные работы обучающихся, включая ВКР и диссертационные работы, участвовал(а) в защитах ВКР и диссертационных работ'}\n",
    "pq_decoder = {1: 'Проводил(а) разные виды учебных и производственных практик, школ, экспедиций'}\n",
    "ps_decoder = {1: 'Нет'}\n",
    "pt_decoder = {1: 'Не выполнял(а) иную образовательную деятельность'}\n",
    "\n",
    "report['PO'] = report['PO'].map(po_decoder)\n",
    "report['PP'] = report['PP'].map(pp_decoder)\n",
    "report['PQ'] = report['PQ'].map(pq_decoder)\n",
    "report['PS'] = report['PS'].map(ps_decoder)\n",
    "report['PT'] = report['PT'].map(pt_decoder)\n",
    "\n",
    "origin = pd.read_excel(wd + '/data/report.xlsx', header=None)\n",
    "header = origin.columns\n",
    "origin.columns = [xl_col_to_name(x) for x in header]\n",
    "columns = ['JC', 'JD', 'JE', 'JF', 'JG', 'JH',\n",
    "           'JI', 'JJ', 'JK', 'JL', 'JM', 'JN',\n",
    "           'JO', 'JP', 'JQ', 'JR', 'JS', 'JT',\n",
    "           'JU', 'JV', 'JW', 'JX', 'JY', 'JZ',\n",
    "           'KA', 'KB', 'KC', 'KE', 'KF',\n",
    "           'KG', 'KH', 'KI', 'KJ', 'KK', 'KL',\n",
    "           'KM', 'KN', 'KO', 'KP', 'KQ', 'KR',\n",
    "           'KS', 'KT', 'KU', 'KV', 'KW', 'KX',\n",
    "           'KY', 'KZ', 'LB', 'LC', 'LD',\n",
    "           'LF', 'LE', 'LI', 'LJ',\n",
    "           'LK', 'LL', 'LM', 'LN', 'LO', 'LP',\n",
    "           'LQ', 'LR', 'LS', 'LT', 'LV',\n",
    "           'LW', 'LX']\n",
    "origin = origin.loc[:, columns]\n",
    "mapper = dict(origin.iloc[1])\n",
    "\n",
    "for k, v in mapper.items():\n",
    "    mapper[k] = str(v.split(' - ')[-1])\n",
    "\n",
    "mapper['LW'] = 'Работа в интересах НИУ ВШЭ и другие внешние организации и ведомства (привидите краткое описание деятельности/проекта, его направление и результаты): '\n",
    "mapper['LX'] = 'Работа в интересах НИУ ВШЭ и другие внешние организации и ведомства (привидите краткое описание деятельности/проекта, его направление и результаты): '\n",
    "\n",
    "for column in columns:\n",
    "    if not column in ['KE', 'LB', 'LH', 'LI', 'LV', 'LW', 'LX', 'LJ']:\n",
    "        report[column] = report[column].map({1: mapper[column]}) \n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "report['LELH'] = report['LE'] + ': ' + report['LH']\n",
    "report['LX'] = mapper['LX'] + report['LX']\n",
    "report['LW'] = mapper['LW'] + report['LW']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb57481",
   "metadata": {},
   "source": [
    "## Parse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20112849",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheets_to_consider = ['1.1.', '1.2.', '1.3.', '1.4.', '1.5.',\n",
    "                      '2', '3',\n",
    "                      '4.1.', '4.2.', '4.3.', '4.4.', '4.5.',\n",
    "                      '5.1.', '5.2.', '5.3.', '5.4.', '5.5.', '5.6.',\n",
    "                      '6.1.1.', '6.1.2.', '6.1.3.', '6.1.4.', '6.1.5.',\n",
    "                      '6.2.', '6.3.',\n",
    "                      '7.', '7.1.', '7.2.',\n",
    "                      '8', '9', '10']\n",
    "\n",
    "for subdivision in subdivisions:\n",
    "    file_name = wd + '/results/report/' + subdivision + '_отчет_2022' + '.xlsx'\n",
    "    # Copy the teplate for each subdivision\n",
    "    copyfile(wd + '/templates/' + 'template_report_final.xlsx', file_name)\n",
    "    # Load the file\n",
    "    workbook = load_workbook(file_name)\n",
    "    # Select observations\n",
    "    subset = report[report['K'] == subdivision]\n",
    "\n",
    "    for sheet_name in sheets_to_consider:\n",
    "        # Parse a particular sheet and save it as a DataFrame\n",
    "        sheet = task.parse(sheet_name=sheet_name, skiprows=1)\n",
    "        # Drop NaNs\n",
    "        sheet.dropna(how='all', inplace=True)\n",
    "        # Drop useless column\n",
    "        sheet.drop(columns='№', inplace=True)\n",
    "        # Save headers\n",
    "        header = sheet.columns\n",
    "\n",
    "        # Initialize a list for DataFrames\n",
    "        dfs = []\n",
    "\n",
    "        # Iterate over each row\n",
    "        for i, data in sheet.iterrows():\n",
    "            values = data.values.tolist()\n",
    "            if sheet_name == '4.1.':\n",
    "                if pd.Series(values).isna().sum() >= 1:\n",
    "                    values.pop()\n",
    "                    values.extend(['NA'])\n",
    "                # Select needed columns and drop missing values\n",
    "                df = subset.loc[:, values].dropna(thresh=2)\n",
    "                # Use initial column names\n",
    "                df.columns = header\n",
    "                # Append the obtained DataFrame to the list of DataFrames\n",
    "                dfs.append(df)\n",
    "            elif sheet_name in ['1.1.', '1.2.', '1.3.', '1.4.', '1.5.',\n",
    "                                '5.2.', '5.4.', '5.5.', '5.6.',\n",
    "                                '6.1.1.', '6.1.2.', '6.1.3.', '6.1.4.', '6.1.5.',\n",
    "                                '6.2.', '6.3.',\n",
    "                                '7.2.',\n",
    "                                '8', '9', '10']:\n",
    "                # Select needed columns and drop rows with less than 1 non-missing value\n",
    "                df = subset.loc[:, data.values].dropna(thresh=1)\n",
    "                # Use initial column names\n",
    "                df.columns = header\n",
    "                # Append the obtained DataFrame to the list of DataFrames\n",
    "                dfs.append(df) \n",
    "            else:\n",
    "                # Select needed columns and drop rows with less than 2 non-missing value\n",
    "                df = subset.loc[:, data.values].dropna(thresh=2)\n",
    "                # Use initial column names\n",
    "                df.columns = header\n",
    "                # Append the obtained DataFrame to the list of DataFrames\n",
    "                dfs.append(df)\n",
    "\n",
    "        # Concat the DataFrames\n",
    "        dfs = pd.concat(dfs, ignore_index=True)\n",
    "        # Save index as a column\n",
    "        dfs.reset_index(inplace=True)\n",
    "        # Change index so that it starts with 1\n",
    "        dfs['index'] = dfs['index'] + 1\n",
    "        \n",
    "        # Get access to the particular sheet\n",
    "        worksheet = workbook[sheet_name]\n",
    "        # Turn the DataFrame into Generator object dataframe_to_rows\n",
    "        rows = dataframe_to_rows(dfs, index=False, header=False)\n",
    "        # Write data directly in the current Excel sheet\n",
    "        for r_idx, row in enumerate(rows, 3):\n",
    "            for c_idx, value in enumerate(row, 1):\n",
    "                worksheet.cell(row=r_idx, column=c_idx, value=value)\n",
    "    # Save the updated Excel file\n",
    "    workbook.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53781273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
